---
layout: paper
title: About
---

<div class="about">
  <h2>About the Research</h2>
  <p>This research was conducted as part of a study on mechanistic interpretability of large language models. The study represents a significant contribution to the field of AI interpretability and has important implications for understanding how neural networks encode reasoning processes.</p>
  
  <h2>Research Team</h2>
  <div class="author-card">
    <img src="/assets/images/author-photos/anonymous.jpg" alt="Anonymous Author" class="author-photo">
    <h3 class="author-name">Anonymous Author(s)</h3>
    <p class="author-title">Research Team</p>
    <p class="author-bio">This research was conducted by anonymous authors as part of a submission to the 39th Conference on Neural Information Processing Systems (NeurIPS 2025). The authors have expertise in machine learning, mechanistic interpretability, and large language model research.</p>
    <div class="author-links">
      <a href="mailto:email">Email</a>
      <a href="#" target="_blank">Google Scholar</a>
      <a href="#" target="_blank">ORCID</a>
      <a href="#" target="_blank">GitHub</a>
    </div>
  </div>
  
  <h2>Institutional Affiliation</h2>
  <p>This research was conducted at an academic institution with expertise in machine learning and AI research. The work represents a collaborative effort in the field of mechanistic interpretability.</p>
  
  <h2>Funding and Support</h2>
  <p>This research was supported by institutional funding and resources. We gratefully acknowledge the contributions of the research community and the open-source datasets and tools that made this work possible.</p>
  
  <div class="acknowledgments">
    <h3>Acknowledgments</h3>
    <p>We would like to thank the creators of the PTS dataset and the Qwen3-0.6B model for making their resources publicly available. Special thanks to the mechanistic interpretability community for their foundational work on understanding neural network representations, and to the reviewers and conference organizers for their valuable feedback.</p>
  </div>
  
  <h2>Research Contributions</h2>
  <p>Our contributions are as follows:</p>
  <ul>
    <li>We refine and preprocess an open-source dataset of pivotal tokens and their surrounding contexts</li>
    <li>We propose a probing framework for classifying pivotal vs. non-pivotal activations in Qwen3-0.6B</li>
    <li>We provide preliminary evidence that pivotalness corresponds to weighted directions in the latent space across multiple layers</li>
    <li>We discuss hypotheses for steering pivotal directions during generation and for aggregating probes across layers to improve performance</li>
  </ul>
  
  <h2>Future Work</h2>
  <p>By reframing PTS through probing, we aim to lay the groundwork for mechanistic interventions into model reasoning. Future work will explore:</p>
  <ul>
    <li>Cross-layer aggregation methods for improved probe performance</li>
    <li>Representation steering techniques for altering reasoning trajectories</li>
    <li>Scalable approximations to PTS for real-time applications</li>
    <li>Applications to larger models and more complex reasoning tasks</li>
  </ul>
  
  <h2>Contact Information</h2>
  <p>For questions about this research or to request additional information, please contact the corresponding author through the provided email address. We will publicly release code, data, and other artifacts upon acceptance of the paper.</p>
</div>
